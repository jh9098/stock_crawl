import pandas as pd
import ast

# 1. ê¸°ì¡´ í‚¤ì›Œë“œ ì„¸íŠ¸
STOCK_SEARCH_KEYWORDS = set([
    "ì½”ìŠ¤í”¼", "ì½”ìŠ¤ë‹¥", "í™˜ìœ¨", "ê¸ˆë¦¬ì¸ìƒ", "FOMC", "ì™¸êµ­ì¸ ìˆœë§¤ìˆ˜", "ë°˜ë„ì²´",
    "HBM", "AIë°˜ë„ì²´", "2ì°¨ì „ì§€", "ë°”ì´ì˜¤", "ì œì•½", "ë°¸ë¥˜ì—…", "ê¸°ì—… ì‹¤ì "
])

# 2. ìµœì‹  ë‰´ìŠ¤ ë°ì´í„° ë¡œë“œ (ê²½ë¡œëŠ” ê°ì ë§ê²Œ ìˆ˜ì •)
CSV_PATH = r"P:\stock_crawl\backend\output\merged_no_duplicate.csv"
df = pd.read_csv(CSV_PATH, encoding="utf-8")

# 3. ìµœê·¼ 7ì¼ ë˜ëŠ” 30ì¼ ë“± ì›í•˜ëŠ” ê¸°ê°„ë§Œ í•„í„°ë§ (ì˜ˆ: 30ì¼)
df['published_at'] = pd.to_datetime(df['published_at'])
date_limit = pd.Timestamp.now() - pd.Timedelta(days=30)
df = df[df['published_at'] >= date_limit]

# 4. analysis_keywords ì»¬ëŸ¼ì—ì„œ ì „ì²´ í‚¤ì›Œë“œ ì¶”ì¶œ ë° ì§‘ê³„
all_keywords = []
for x in df['analysis_keywords']:
    # ë¬¸ìì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    try:
        kws = ast.literal_eval(str(x))
        all_keywords.extend([k for k in kws if isinstance(k, str)])
    except Exception:
        continue

# 5. ì§‘ê³„ (Series.value_counts)
import collections
keyword_counts = collections.Counter(all_keywords)

# 6. ê¸°ì¡´ í‚¤ì›Œë“œì—ëŠ” ì—†ëŠ” ì¸ê¸° í‚¤ì›Œë“œ ì¶”ì¶œ (ìµœëŒ€ 20ê°œ ì˜ˆì‹œ)
recommended_keywords = [
    (kw, count)
    for kw, count in keyword_counts.most_common(50)
    if kw not in STOCK_SEARCH_KEYWORDS and len(kw) > 1
][:20]

print("ğŸ’¡ ì¶”ì²œ ê²€ìƒ‰ í‚¤ì›Œë“œ (ìµœê·¼ 30ì¼ ê¸°ì¤€, ê¸°ì¡´ì— ì—†ëŠ” ê²ƒ):")
for kw, count in recommended_keywords:
    print(f"- {kw} ({count}íšŒ)")

# í•„ìš”ì‹œ ê²°ê³¼ë¥¼ txt/csvë¡œ ì €ì¥í•´ë„ ë¨
