
---

### ğŸ“ 2. `trends_dashboard.py` (ë°ì´í„° ì‹œê°í™” ëŒ€ì‹œë³´ë“œ)

ì´ íŒŒì¼ì€ Render Web Serviceë‚˜ Streamlit Community Cloudì— ë°°í¬í•  ëŒ€ì‹œë³´ë“œ ì½”ë“œì…ë‹ˆë‹¤. JSONBin.ioì—ì„œ ë°ì´í„°ë¥¼ ì§ì ‘ ì½ì–´ì˜µë‹ˆë‹¤.
**(í”„ë¡œì íŠ¸ì˜ `dashboard/` í´ë”ì— ì €ì¥)**

```python
# dashboard/trends_dashboard.py
# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import plotly.express as px
import os
import csv
import numpy as np
import ast
from pathlib import Path
from math import log
import requests
import json

# =========================== ê¸°ë³¸ ì„¤ì • ===========================
st.set_page_config(
    page_title="ë‰´ìŠ¤ íŠ¸ë Œë“œ ë¶„ì„ ëŒ€ì‹œë³´ë“œ",
    page_icon="ğŸ“ˆ",
    layout="wide",
)

# --- JSONBin.io ì„¤ì • ---
# ğŸš¨ ì•„ë˜ ê°’ë“¤ì€ ë°°í¬ í”Œë«í¼ì˜ Secretìœ¼ë¡œ ì„¤ì •í•˜ëŠ” ê²ƒì´ ê°€ì¥ ì•ˆì „í•©ë‹ˆë‹¤.
# ë¡œì»¬ í…ŒìŠ¤íŠ¸ ì‹œì—ëŠ” ì§ì ‘ ì…ë ¥í•˜ê±°ë‚˜ í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì •í•˜ì„¸ìš”.
JSONBIN_API_KEY = os.getenv("JSONBIN_API_KEY", "ì—¬ê¸°ì—_JSONBIN_API_KEYë¥¼_ì…ë ¥") 
JSONBIN_BIN_ID = os.getenv("JSONBIN_BIN_ID", "ì—¬ê¸°ì—_JSONBIN_BIN_IDë¥¼_ì…ë ¥")

# ----- ë””í´íŠ¸ ê°’ -----
DEFAULT_TOP_N_KEY_ORG = 15
DEFAULT_RECENT_DAYS   = 7
DEFAULT_PREV_DAYS     = 7
EPS = 1e-6

STOP_KEYWORDS = {
    "í•œêµ­", "ì •ë¶€", "ì •ì±…", "ë°œí‘œ", "ê´€ë ¨", "ì‹œì¥", "ì¦ì‹œ", "ê²½ì œ", "ì£¼ì‹", "ì´ë‚ ",
    "ê¸°ì‚¬", "ë¶„ì„", "ì—…ê³„", "íšŒì‚¬", "ê¸ˆìœµ", "íˆ¬ì", "ì‹¤ì "
}

# =========================== ë°ì´í„° ë¡œë”© í•¨ìˆ˜ ===========================
def safe_literal_eval(val):
    try:
        return ast.literal_eval(str(val))
    except (ValueError, SyntaxError, TypeError):
        return []

@st.cache_data(ttl=600) # 10ë¶„ë§ˆë‹¤ ë°ì´í„° ìƒˆë¡œê³ ì¹¨
def load_data_from_bin(api_key, bin_id):
    """JSONBinì—ì„œ ìµœì‹  ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ì „ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    if "ì—¬ê¸°ì—" in api_key or "ì—¬ê¸°ì—" in bin_id:
        st.error("JSONBin.io API í‚¤ì™€ Bin IDë¥¼ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.")
        return None

    headers = {'X-Master-Key': api_key, 'X-Bin-Versioning': 'false'}
    url = f"https://api.jsonbin.io/v3/b/{bin_id}/latest"
    try:
        req = requests.get(url, headers=headers, timeout=15)
        req.raise_for_status()
        data = req.json()
        
        df = pd.DataFrame(data)

        # ë‚ ì§œì²˜ë¦¬
        df['analysis_date'] = pd.to_datetime(df['published_at'], errors='coerce').dt.date
        df.dropna(subset=['analysis_date'], inplace=True)

        # ë¦¬ìŠ¤íŠ¸ ì»¬ëŸ¼ ì²˜ë¦¬
        df['analysis_keywords'] = df['analysis_keywords'].apply(safe_literal_eval)
        df['analysis_orgs']     = df['analysis_orgs'].apply(safe_literal_eval)

        return df
    except Exception as e:
        st.error(f"ì›ê²© ë°ì´í„° ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

# =========================== ë°ì´í„° ë¡œë“œ ===========================
df = load_data_from_bin(JSONBIN_API_KEY, JSONBIN_BIN_ID)

st.title("ğŸ“ˆ ë‰´ìŠ¤ íŠ¸ë Œë“œ ë¶„ì„ ëŒ€ì‹œë³´ë“œ (ìë™ ì—…ë°ì´íŠ¸)")

if df is None or df.empty:
    st.warning("ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
    st.stop()
    
# (ì´í•˜ ëŒ€ì‹œë³´ë“œ UI ì½”ë“œëŠ” ê¸°ì¡´ `trends_dashboard.py`ì™€ ê±°ì˜ ë™ì¼í•˜ê²Œ ì‚¬ìš© ê°€ëŠ¥)
# (ê²½ë¡œ ì„¤ì • ë° ì¼ë¶€ ë¡œì§ë§Œ ì›ê²© ë°ì´í„°ì— ë§ê²Œ ìˆ˜ì •ë¨)

# =========================== ì‚¬ì´ë“œë°” í•„í„° ===========================
st.sidebar.header("ğŸ“Š ê¸°ë³¸ í•„í„°")

min_date = df['analysis_date'].min()
max_date = df['analysis_date'].max()

date_range = st.sidebar.date_input(
    "ë‚ ì§œ ë²”ìœ„ ì„ íƒ",
    value=(min_date, max_date), min_value=min_date, max_value=max_date
)

if len(date_range) != 2:
    st.stop()

start_date, end_date = date_range
filtered_df = df[(df['analysis_date'] >= start_date) & (df['analysis_date'] <= end_date)].copy()

st.sidebar.markdown("---")
st.sidebar.subheader("ğŸ”¤ í‚¤ì›Œë“œ/ê¸°ê´€ í‘œì‹œ ê°œìˆ˜")
TOP_N_KEY_ORG = st.sidebar.number_input("ìƒìœ„ ê°œìˆ˜", 5, 50, DEFAULT_TOP_N_KEY_ORG, 1)

st.sidebar.markdown("---")
st.sidebar.subheader("ğŸ”¥ ëª¨ë©˜í…€ ë¶„ì„ ì„¤ì •")
recent_days = st.sidebar.number_input("ìµœê·¼ Nì¼", 3, 30, DEFAULT_RECENT_DAYS, 1)
prev_days   = st.sidebar.number_input("ì§ì „ Nì¼", 3, 30, DEFAULT_PREV_DAYS, 1)

# =========================== ë°ì´í„° ìš”ì•½ ===========================
st.success(f"ì´ **{len(filtered_df)}ê°œ ê¸°ì‚¬** ë¶„ì„ (ê¸°ê°„: {start_date} ~ {end_date})")

# =========================== í‚¤ì›Œë“œ/ê¸°ê´€ ì‹œê³„ì—´ ===========================
col1, col2 = st.columns(2)

with col1:
    st.subheader("ğŸ—“ï¸ ì£¼ìš” í‚¤ì›Œë“œ ì–¸ê¸‰ëŸ‰")
    exploded_kw = filtered_df.explode('analysis_keywords').dropna(subset=['analysis_keywords'])
    exploded_kw = exploded_kw[~exploded_kw['analysis_keywords'].isin(STOP_KEYWORDS)]
    if not exploded_kw.empty:
        daily_counts_kw = exploded_kw.groupby(['analysis_date', 'analysis_keywords']).size().reset_index(name='count')
        top_kw = daily_counts_kw.groupby('analysis_keywords')['count'].sum().nlargest(TOP_N_KEY_ORG).index
        top_kw_df = daily_counts_kw[daily_counts_kw['analysis_keywords'].isin(top_kw)]
        if not top_kw_df.empty:
            fig_kw = px.line(top_kw_df, x='analysis_date', y='count', color='analysis_keywords', markers=True)
            st.plotly_chart(fig_kw, use_container_width=True)

with col2:
    st.subheader("ğŸ¢ ì£¼ìš” ê¸°ê´€/ê¸°ì—… ì–¸ê¸‰ëŸ‰")
    exploded_org = filtered_df.explode('analysis_orgs').dropna(subset=['analysis_orgs'])
    if not exploded_org.empty:
        daily_counts_org = exploded_org.groupby(['analysis_date', 'analysis_orgs']).size().reset_index(name='count')
        top_org = daily_counts_org.groupby('analysis_orgs')['count'].sum().nlargest(TOP_N_KEY_ORG).index
        top_org_df = daily_counts_org[daily_counts_org['analysis_orgs'].isin(top_org)]
        if not top_org_df.empty:
            fig_org = px.line(top_org_df, x='analysis_date', y='count', color='analysis_orgs', markers=True)
            st.plotly_chart(fig_org, use_container_width=True)

# (ì´í•˜ ëª¨ë©˜í…€ ë¶„ì„ ë“± ë‹¤ë¥¸ ì°¨íŠ¸ë“¤ë„ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ êµ¬í˜„ ê°€ëŠ¥)