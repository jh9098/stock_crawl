# dashboard/trends_dashboard.py
# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import plotly.express as px
import os
import csv
import numpy as np
import ast
from pathlib import Path
from math import log
import requests # requests ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ í™•ì¸

# =========================== ê¸°ë³¸ ì„¤ì • ===========================
st.set_page_config(
    page_title="ë‰´ìŠ¤ íŠ¸ë Œë“œ ë¶„ì„ ëŒ€ì‹œë³´ë“œ",
    page_icon="ğŸ“ˆ",
    layout="wide",
)

# --- [í•µì‹¬ ìˆ˜ì •] GitHub Raw URLì—ì„œ ë°ì´í„° ë¡œë“œ ---
# ğŸš¨ ì•„ë˜ URLì˜ 'YourUsername/YourRepoName' ë¶€ë¶„ì„ 
#    ë³¸ì¸ì˜ ì‹¤ì œ GitHub ì‚¬ìš©ìëª…ê³¼ ì €ì¥ì†Œ ì´ë¦„ìœ¼ë¡œ ë°˜ë“œì‹œ ë°”ê¿”ì£¼ì„¸ìš”!
# ì˜ˆì‹œ: "https://raw.githubusercontent.com/jh9098/stock_crawl/main/backend/output/aggregated/aggregated_stock_data.csv"
DATA_URL = "https://raw.githubusercontent.com/jh9098/stock_crawl/main/backend/output/aggregated/aggregated_stock_data.csv"

# ----- ê²½ë¡œ ì„¤ì • (ì½”ìŠ¤í”¼/ì½”ìŠ¤ë‹¥ íŒŒì¼ìš©) -----
# ì´ íŒŒì¼(trends_dashboard.py)ì´ ìˆëŠ” ìœ„ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê²½ë¡œë¥¼ ì¡ìŠµë‹ˆë‹¤.
DASHBOARD_ROOT = os.path.dirname(os.path.abspath(__file__))
KOSPI_TXT   = os.path.join(DASHBOARD_ROOT, "ì½”ìŠ¤í”¼.txt")
KOSDAQ_TXT  = os.path.join(DASHBOARD_ROOT, "ì½”ìŠ¤ë‹¥.txt")

# ----- ë””í´íŠ¸ ê°’ -----
DEFAULT_TOP_N_KEY_ORG = 15
DEFAULT_TOP_N_STOCKS  = 15
DEFAULT_RECENT_DAYS   = 7
DEFAULT_PREV_DAYS     = 7
EPS = 1e-6

STOP_KEYWORDS = {
    "í•œêµ­", "ì •ë¶€", "ì •ì±…", "ë°œí‘œ", "ê´€ë ¨", "ì‹œì¥", "ì¦ì‹œ", "ê²½ì œ", "ì£¼ì‹", "ì´ë‚ ",
    "ê¸°ì‚¬", "ë¶„ì„", "ì—…ê³„", "íšŒì‚¬", "ê¸ˆìœµ", "íˆ¬ì", "ì‹¤ì "
}

# =========================== ìœ í‹¸ í•¨ìˆ˜ ===========================
def safe_literal_eval(val):
    """CSVì—ì„œ ì½ì€ ë¦¬ìŠ¤íŠ¸ í˜•íƒœì˜ ë¬¸ìì—´ -> ì‹¤ì œ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    try:
        # nan ê°™ì€ float íƒ€ì…ì´ ë“¤ì–´ì˜¬ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ë¬¸ìì—´ë¡œ ë¨¼ì € ë³€í™˜
        return ast.literal_eval(str(val))
    except (ValueError, SyntaxError, TypeError):
        return []

@st.cache_data(ttl=600) # 10ë¶„ë§ˆë‹¤ GitHubì—ì„œ ë°ì´í„° ìƒˆë¡œê³ ì¹¨
def load_data_from_github(url):
    """GitHub Raw URLì—ì„œ ìµœì‹  CSV ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ì „ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    try:
        df = pd.read_csv(url)
        
        # ë‚ ì§œì²˜ë¦¬
        published_dt = pd.to_datetime(df['published_at'], errors='coerce')
        crawled_dt   = pd.to_datetime(df['crawled_at'],   errors='coerce')
        df['analysis_date'] = np.where(pd.notna(published_dt), published_dt, crawled_dt)
        df['analysis_date'] = pd.to_datetime(df['analysis_date']).dt.date
        df.dropna(subset=['analysis_date'], inplace=True)

        # ë¦¬ìŠ¤íŠ¸ ì»¬ëŸ¼ ì²˜ë¦¬
        df['analysis_keywords'] = df['analysis_keywords'].apply(safe_literal_eval)
        df['analysis_orgs']     = df['analysis_orgs'].apply(safe_literal_eval)

        return df
    except Exception as e:
        st.error(f"GitHubì—ì„œ ë°ì´í„° ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        st.info("ë°ì´í„° URLì´ ì •í™•í•œì§€, ê·¸ë¦¬ê³  GitHub ì €ì¥ì†Œì˜ í•´ë‹¹ ê²½ë¡œì— CSV íŒŒì¼ì´ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return None

@st.cache_data
def load_stock_names(kospi_path: str, kosdaq_path: str):
    """ì½”ìŠ¤í”¼/ì½”ìŠ¤ë‹¥ í…ìŠ¤íŠ¸ íŒŒì¼ì—ì„œ ì¢…ëª©ëª… ë¦¬ìŠ¤íŠ¸ ë¡œë“œ"""
    names = []
    for p in [kospi_path, kosdaq_path]:
        try:
            # ì›¹ ë°°í¬ í™˜ê²½ì„ ê³ ë ¤í•˜ì—¬ Path ì‚¬ìš©
            txt_path = Path(p)
            if txt_path.is_file():
                txt = txt_path.read_text(encoding='utf-8').splitlines()
                names.extend([x.strip() for x in txt if x.strip()])
            else:
                 st.warning(f"ì¢…ëª© ë¦¬ìŠ¤íŠ¸ íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {p}")
        except Exception as e:
            st.warning(f"ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ë¡œë”© ì¤‘ ì˜¤ë¥˜ ({p}): {e}")
    return sorted(set(names))

def extract_stock_mentions(org_list, stock_set):
    """ë¶„ì„ëœ ê¸°ê´€/ê¸°ì—… ë¦¬ìŠ¤íŠ¸ ì¤‘ ì¢…ëª©ëª…ë§Œ ì¶”ì¶œ"""
    if not isinstance(org_list, list):
        return []
    # analysis_orgsì— ìˆëŠ” ì´ë¦„ì´ stock_setì— í¬í•¨ë˜ëŠ” ê²½ìš°ë§Œ í•„í„°ë§
    return [org for org in org_list if org in stock_set]


# =========================== ë°ì´í„° ë¡œë“œ ===========================
df = load_data_from_github(DATA_URL)
stock_list = load_stock_names(KOSPI_TXT, KOSDAQ_TXT)
stock_set  = set(stock_list)

st.title("ğŸ“ˆ ë‰´ìŠ¤ íŠ¸ë Œë“œ ë¶„ì„ ëŒ€ì‹œë³´ë“œ (ìë™ ì—…ë°ì´íŠ¸)")

if df is None or df.empty:
    st.warning("ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. GitHub Actionsê°€ ì•„ì§ ì‹¤í–‰ë˜ì§€ ì•Šì•˜ê±°ë‚˜, ë°ì´í„° ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    st.stop()

# =========================== ì‚¬ì´ë“œë°” í•„í„° ===========================
st.sidebar.header("ğŸ“Š ê¸°ë³¸ í•„í„°")

min_date = df['analysis_date'].min()
max_date = df['analysis_date'].max()

date_range = st.sidebar.date_input(
    "ë‚ ì§œ ë²”ìœ„ ì„ íƒ",
    value=(min_date, max_date), min_value=min_date, max_value=max_date
)

if len(date_range) != 2:
    st.stop()

start_date, end_date = date_range
filtered_df = df[(df['analysis_date'] >= start_date) & (df['analysis_date'] <= end_date)].copy()

st.sidebar.markdown("---")
st.sidebar.subheader("ğŸ”¤ í‘œì‹œ ê°œìˆ˜ ì„¤ì •")
TOP_N_KEY_ORG = st.sidebar.number_input("í‚¤ì›Œë“œ/ê¸°ê´€ ìƒìœ„ ê°œìˆ˜", 5, 50, DEFAULT_TOP_N_KEY_ORG, 1)
TOP_N_STOCKS = st.sidebar.number_input("ì‹œê³„ì—´ ìƒìœ„ ì¢…ëª© ê°œìˆ˜", 5, 50, DEFAULT_TOP_N_STOCKS, 1)

st.sidebar.markdown("---")
st.sidebar.subheader("ğŸ”¥ ëª¨ë©˜í…€ ë¶„ì„ ì„¤ì •")
recent_days = st.sidebar.number_input("ìµœê·¼ Nì¼", 3, 30, DEFAULT_RECENT_DAYS, 1)
prev_days   = st.sidebar.number_input("ì§ì „ Nì¼", 3, 30, DEFAULT_PREV_DAYS, 1)

# =========================== ë°ì´í„° ìš”ì•½ ===========================
st.success(f"ì´ **{len(filtered_df)}ê°œ ê¸°ì‚¬** ë¶„ì„ (ê¸°ê°„: {start_date} ~ {end_date})")

# =========================== ì¢…ëª© ë¶„ì„ ê³µí†µ ì¤€ë¹„ ===========================
if not stock_set:
    st.warning("ì½”ìŠ¤í”¼/ì½”ìŠ¤ë‹¥ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. txt íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
else:
    # analysis_orgs ì—ì„œ ì£¼ì‹ ì¢…ëª©ë§Œ í•„í„°ë§í•˜ì—¬ 'stock_mentions' ì»¬ëŸ¼ ìƒì„±
    filtered_df['stock_mentions'] = filtered_df['analysis_orgs'].apply(lambda orgs: extract_stock_mentions(orgs, stock_set))

# =========================== í‚¤ì›Œë“œ/ê¸°ê´€/ì¢…ëª© ì‹œê³„ì—´ ===========================
st.markdown("---")
st.header("ğŸ“Š ì‹œê³„ì—´ íŠ¸ë Œë“œ ë¶„ì„")
col1, col2, col3 = st.columns(3)

with col1:
    st.subheader("ğŸ—“ï¸ ì£¼ìš” í‚¤ì›Œë“œ")
    exploded_kw = filtered_df.explode('analysis_keywords').dropna(subset=['analysis_keywords'])
    exploded_kw = exploded_kw[~exploded_kw['analysis_keywords'].isin(STOP_KEYWORDS | stock_set)]
    if not exploded_kw.empty:
        daily_counts_kw = exploded_kw.groupby(['analysis_date', 'analysis_keywords']).size().reset_index(name='count')
        top_kw = daily_counts_kw.groupby('analysis_keywords')['count'].sum().nlargest(TOP_N_KEY_ORG).index
        top_kw_df = daily_counts_kw[daily_counts_kw['analysis_keywords'].isin(top_kw)]
        if not top_kw_df.empty:
            fig_kw = px.line(top_kw_df, x='analysis_date', y='count', color='analysis_keywords', markers=True, title=f"ìƒìœ„ {TOP_N_KEY_ORG} í‚¤ì›Œë“œ ì–¸ê¸‰ ì¶”ì´")
            st.plotly_chart(fig_kw, use_container_width=True)

with col2:
    st.subheader("ğŸ¢ ì£¼ìš” ê¸°ê´€ (Non-stock)")
    exploded_org = filtered_df.explode('analysis_orgs').dropna(subset=['analysis_orgs'])
    exploded_org = exploded_org[~exploded_org['analysis_orgs'].isin(stock_set)]
    if not exploded_org.empty:
        daily_counts_org = exploded_org.groupby(['analysis_date', 'analysis_orgs']).size().reset_index(name='count')
        top_org = daily_counts_org.groupby('analysis_orgs')['count'].sum().nlargest(TOP_N_KEY_ORG).index
        top_org_df = daily_counts_org[daily_counts_org['analysis_orgs'].isin(top_org)]
        if not top_org_df.empty:
            fig_org = px.line(top_org_df, x='analysis_date', y='count', color='analysis_orgs', markers=True, title=f"ìƒìœ„ {TOP_N_KEY_ORG} ê¸°ê´€ ì–¸ê¸‰ ì¶”ì´")
            st.plotly_chart(fig_org, use_container_width=True)

with col3:
    st.subheader("ğŸ“ˆ ì£¼ìš” ì¢…ëª©")
    exploded_stock = filtered_df.explode('stock_mentions').dropna(subset=['stock_mentions'])
    if not exploded_stock.empty:
        daily_counts_stock = exploded_stock.groupby(['analysis_date', 'stock_mentions']).size().reset_index(name='count')
        top_stock = daily_counts_stock.groupby('stock_mentions')['count'].sum().nlargest(TOP_N_STOCKS).index
        top_stock_df = daily_counts_stock[daily_counts_stock['stock_mentions'].isin(top_stock)]
        if not top_stock_df.empty:
            fig_stock = px.line(top_stock_df, x='analysis_date', y='count', color='stock_mentions', markers=True, title=f"ìƒìœ„ {TOP_N_STOCKS} ì¢…ëª© ì–¸ê¸‰ ì¶”ì´")
            st.plotly_chart(fig_stock, use_container_width=True)

# (ì´í•˜ ëª¨ë©˜í…€ ë¶„ì„ ë“± ë‹¤ë¥¸ ê¸°ëŠ¥ë“¤ë„ ìœ„ì™€ ìœ ì‚¬í•œ ë°©ì‹ìœ¼ë¡œ êµ¬í˜„ ê°€ëŠ¥)